import json
import uuid
from datetime import datetime
from typing import Dict, Any, Optional, AsyncGenerator, List, cast
from enum import Enum
import logging

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

# æ·»åŠ LangGraphç›¸å…³å¯¼å…¥
from src.graph.async_builder import create_graph
from src.graph.types import State
from src.utils.url_param_generator import generate_url_param
from src.server.repositories.session_repository import (
    SessionRepository,
    get_session_repository,
)

# æ·»åŠ LangChainæ¶ˆæ¯ç±»å‹å¯¼å…¥
from langchain_core.messages import BaseMessage, ToolMessage, AIMessageChunk

logger = logging.getLogger(__name__)


# è‡ªå®šä¹‰JSONç¼–ç å™¨
class CustomJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, uuid.UUID):
            return str(obj)
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)


def safe_json_dumps(obj):
    """å®‰å…¨çš„JSONåºåˆ—åŒ–"""
    return json.dumps(obj, cls=CustomJSONEncoder, ensure_ascii=False)


# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/research", tags=["research"])


# SSEäº‹ä»¶ç±»å‹å®šä¹‰
class SSEEventType(Enum):
    NAVIGATION = "navigation"
    METADATA = "metadata"
    NODE_START = "node_start"
    NODE_COMPLETE = "node_complete"
    PLAN_GENERATED = "plan_generated"
    SEARCH_RESULTS = "search_results"
    AGENT_OUTPUT = "agent_output"
    MESSAGE_CHUNK = "message_chunk"
    ARTIFACT = "artifact"
    PROGRESS = "progress"
    INTERRUPT = "interrupt"  # ğŸ”¥ æ·»åŠ interruptäº‹ä»¶ç±»å‹
    COMPLETE = "complete"
    ERROR = "error"


# è¯·æ±‚æ¨¡å‹
class ActionType(Enum):
    CREATE = "create"
    CONTINUE = "continue"
    FEEDBACK = "feedback"
    MODIFY = "modify"


class ResearchStreamRequest(BaseModel):
    action: ActionType
    message: str
    url_param: Optional[str] = None
    thread_id: Optional[str] = None
    frontend_uuid: str
    frontend_context_uuid: str
    visitor_id: str
    user_id: Optional[str] = None
    config: Dict[str, Any]
    context: Optional[Dict[str, Any]] = None


# LangGraphåŸç”Ÿæ¶ˆæ¯ç±»å‹ - ä¸å†ä½¿ç”¨è‡ªå®šä¹‰dataclass
# æ‰€æœ‰äº‹ä»¶éƒ½ä½¿ç”¨å­—å…¸æ ¼å¼ï¼Œå®Œå…¨å¯¹é½app.pyçš„å®ç°æ¨¡å¼


class ResearchStreamService:
    """çœŸå®çš„ç ”ç©¶æµå¼æœåŠ¡"""

    def __init__(self, session_repo: SessionRepository):
        self.session_repo = session_repo
        self._graph = None

    async def _get_graph(self):
        """è·å–æˆ–åˆ›å»ºLangGraphå®ä¾‹"""
        if self._graph is None:
            self._graph = await create_graph()
        return self._graph

    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        return datetime.utcnow().isoformat() + "Z"

    def _make_research_event(self, event_type: str, data: dict[str, any]):
        """æ„é€ ç ”ç©¶äº‹ä»¶ - å®Œå…¨å‚è€ƒapp.pyçš„_make_eventå®ç°"""
        if data.get("content") == "":
            data.pop("content")
        return {
            "event": event_type,
            "data": safe_json_dumps(data)
        }

    def _create_message_chunk_event(self, message: AIMessageChunk, agent: str, thread_id: str, execution_id: str):
        """åŸºäºLangGraphåŸç”ŸAIMessageChunkåˆ›å»ºæ¶ˆæ¯äº‹ä»¶"""
        return self._make_research_event("message_chunk", {
            "thread_id": thread_id,
            "agent": agent.split(":")[0],  # æå–èŠ‚ç‚¹å
            "id": message.id,
            "role": "assistant", 
            "content": message.content,
            "finish_reason": message.response_metadata.get("finish_reason"),
            "tool_calls": message.tool_calls,
            "metadata": {
                "additional_kwargs": message.additional_kwargs,
                "response_metadata": message.response_metadata,
            },
            "execution_id": execution_id,
            "timestamp": self._get_current_timestamp(),
        })

    def _create_tool_calls_event(self, message: AIMessageChunk, agent: str, thread_id: str, execution_id: str):
        """åˆ›å»ºå·¥å…·è°ƒç”¨äº‹ä»¶"""
        return self._make_research_event("tool_calls", {
            "thread_id": thread_id,
            "agent": agent.split(":")[0],
            "id": message.id,
            "role": "assistant",
            "content": message.content,
            "tool_calls": message.tool_calls,
            "tool_call_chunks": getattr(message, "tool_call_chunks", []),
            "execution_id": execution_id,
            "timestamp": self._get_current_timestamp(),
        })

    def _create_tool_message_event(self, message: ToolMessage, agent: str, thread_id: str, execution_id: str):
        """åˆ›å»ºå·¥å…·ç»“æœäº‹ä»¶"""
        return self._make_research_event("tool_call_result", {
            "thread_id": thread_id,
            "agent": agent.split(":")[0],
            "id": message.id,
            "role": "assistant",
            "content": message.content,
            "tool_call_id": message.tool_call_id,
            "execution_id": execution_id,
            "timestamp": self._get_current_timestamp(),
        })

    async def _process_langgraph_stream(
        self,
        graph,
        initial_state: Dict[str, Any],
        thread_id: str,
        execution_id: str,
        request: ResearchStreamRequest,
        execution_type: str = "continue",
    ) -> AsyncGenerator[Dict[str, str], None]:
        """å¤„ç†LangGraphæµå¼æ‰§è¡Œ - æç®€åŒ–å®ç°ï¼Œå®Œå…¨å‚è€ƒapp.py"""

        # è·å–sessionä¿¡æ¯ç”¨äºæ•°æ®åº“ä¿å­˜
        session = await self.session_repo.get_session_by_thread_id(thread_id)
        if not session:
            raise ValueError(f"Session not found for thread_id: {thread_id}")

        start_time = datetime.utcnow()

        try:
            # å‘é€å¼€å§‹äº‹ä»¶
            yield self._make_research_event("metadata", {
                "execution_id": execution_id,
                "thread_id": thread_id,
                "session_id": session.id,
                "frontend_uuid": request.frontend_uuid,
                "frontend_context_uuid": request.frontend_context_uuid,
                "visitor_id": request.visitor_id,
                "user_id": request.user_id,
                "config_used": request.config,
                "model_info": {
                    "model_name": (
                        request.config.get("model_config", {}).get(
                            "model_name", "claude-3-5-sonnet-20241022"
                        )
                    ),
                    "provider": (
                        request.config.get("model_config", {}).get(
                            "provider", "anthropic"
                        )
                    ),
                    "version": "20241022",
                },
                "estimated_duration": 120,
                "start_time": start_time.isoformat() + "Z",
                "execution_type": execution_type,
                "timestamp": self._get_current_timestamp(),
            })

            # æ‰§è¡ŒLangGraphå·¥ä½œæµ - å®Œå…¨å‚è€ƒapp.pyå®ç°
            config = {"configurable": {"thread_id": thread_id}}

            async for agent, _, event_data in graph.astream(
                initial_state,
                config,
                stream_mode=["messages", "updates"],
                subgraphs=True,
            ):
                # å¤„ç†LangGraphåŸç”Ÿæ¶ˆæ¯äº‹ä»¶
                if not isinstance(event_data, dict):
                    message_chunk, message_metadata = cast(tuple[BaseMessage, dict], event_data)
                    
                    # ä½¿ç”¨LangGraphåŸç”Ÿç±»å‹åˆ¤æ–­
                    if isinstance(message_chunk, ToolMessage):
                        yield self._create_tool_message_event(message_chunk, agent, thread_id, execution_id)
                    elif isinstance(message_chunk, AIMessageChunk):
                        if message_chunk.tool_calls:
                            yield self._create_tool_calls_event(message_chunk, agent, thread_id, execution_id)
                        else:
                            yield self._create_message_chunk_event(message_chunk, agent, thread_id, execution_id)
                    continue
                
                # å¤„ç†updatesäº‹ä»¶ï¼ˆinterruptç­‰ï¼‰
                if isinstance(event_data, dict):
                    if "__interrupt__" in event_data:
                        # å¤„ç†interruptäº‹ä»¶ï¼ˆå®Œå…¨å‚è€ƒapp.pyå®ç°ï¼‰
                        interrupt_data = event_data["__interrupt__"][0]
                        interrupt_value = interrupt_data.value

                        logger.info(f"ğŸ”„ æ”¶åˆ°interruptäº‹ä»¶: {interrupt_value}")

                        # æ£€æŸ¥æ˜¯å¦æ˜¯reaskç±»å‹çš„interrupt
                        if (
                            isinstance(interrupt_value, tuple)
                            and len(interrupt_value) == 2
                            and interrupt_value[0] == "reask"
                        ):
                            # å¤„ç†reask interrupt
                            original_input = interrupt_value[1]
                            yield self._make_research_event("reask", {
                                "thread_id": thread_id,
                                "id": interrupt_data.ns[0],
                                "role": "assistant",
                                "content": "æ­£åœ¨æ¢å¤åŸå§‹è¾“å…¥çŠ¶æ€...",
                                "finish_reason": "reask",
                                "original_input": original_input,
                            })
                        else:
                            # å¤„ç†æ ‡å‡†interrupt
                            if (
                                isinstance(interrupt_value, dict)
                                and "options" in interrupt_value
                            ):
                                message_content = interrupt_value.get(
                                    "message", "Please Review the Plan."
                                )
                                options = interrupt_value.get("options", [])
                            else:
                                # å…¼å®¹æ—§æ ¼å¼
                                message_content = str(interrupt_value)
                                options = [
                                    {"text": "å¼€å§‹ç ”ç©¶", "value": "accepted"},
                                    {"text": "ç¼–è¾‘è®¡åˆ’", "value": "edit_plan"},
                                    {"text": "ç«‹å³ç”ŸæˆæŠ¥å‘Š", "value": "skip_research"},
                                    {"text": "é‡æ–°æé—®", "value": "reask"},
                                ]

                            yield self._make_research_event("interrupt", {
                                "thread_id": thread_id,
                                "id": interrupt_data.ns[0],
                                "role": "assistant",
                                "content": message_content,
                                "finish_reason": "interrupt",
                                "options": options,
                            })

                        # interruptåä¸å‘é€completeäº‹ä»¶ï¼Œç­‰å¾…ç”¨æˆ·åé¦ˆ
                        logger.info(f"ğŸ”„ Interruptå‘é€å®Œæˆï¼Œç­‰å¾…ç”¨æˆ·åé¦ˆ")
                        return

            # æ£€æŸ¥æ˜¯å¦çœŸæ­£å®Œæˆ
            try:
                current_state = await graph.aget_state(config)
                duration_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

                # å‘é€å®Œæˆäº‹ä»¶
                yield self._make_research_event("complete", {
                    "execution_id": execution_id,
                    "thread_id": thread_id,
                    "total_duration_ms": duration_ms,
                    "tokens_consumed": {"input": 0, "output": 0},
                    "total_cost": 0.0,
                    "artifacts_generated": [],
                    "final_status": "completed",
                    "completion_time": self._get_current_timestamp(),
                    "summary": {"nodes_completed": []},
                    "timestamp": self._get_current_timestamp(),
                })

            except Exception as state_error:
                logger.warning(f"âš ï¸ æ— æ³•è·å–LangGraphçŠ¶æ€: {state_error}")

        except Exception as e:
            logger.error(f"LangGraphæ‰§è¡Œé”™è¯¯: {e}")
            yield self._make_research_event("error", {
                "error_code": "LANGGRAPH_EXECUTION_ERROR",
                "error_message": str(e),
                "error_details": {"traceback": str(e)},
                "thread_id": thread_id,
                "execution_id": execution_id,
                "retry_after": None,
                "suggestions": ["æ£€æŸ¥é…ç½®", "é‡è¯•è¯·æ±‚"],
                "timestamp": self._get_current_timestamp(),
            })

    async def create_research_stream(
        self,
        request: ResearchStreamRequest,
        existing_session_id: Optional[int] = None,
        existing_thread_id: Optional[str] = None,
    ) -> AsyncGenerator[Dict[str, str], None]:
        """åˆ›å»ºæ–°çš„ç ”ç©¶æµ"""
        try:
            # è§£æé…ç½® - æ”¯æŒæ–°æ—§æ ¼å¼
            # å¦‚æœæœ‰research_configå­—æ®µï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä»æ‰å¹³åŒ–çš„configä¸­æå–
            if "research_config" in request.config:
                research_config = request.config["research_config"]
            else:
                # ä»æ‰å¹³åŒ–çš„configä¸­æå–researchç›¸å…³é…ç½®
                research_config = {
                    "auto_accepted_plan": request.config.get(
                        "auto_accepted_plan", False
                    ),
                    "enable_background_investigation": request.config.get(
                        "enableBackgroundInvestigation", True
                    ),
                    "report_style": request.config.get("reportStyle", "academic"),
                    "enable_deep_thinking": request.config.get(
                        "enableDeepThinking", False
                    ),
                    "max_plan_iterations": request.config.get("maxPlanIterations", 3),
                    "max_step_num": request.config.get("maxStepNum", 5),
                    "max_search_results": request.config.get("maxSearchResults", 5),
                }

            model_config = request.config.get("model_config", {})
            output_config = request.config.get(
                "output_config",
                {
                    "language": "zh-CN",
                    "output_format": request.config.get("outputFormat", "markdown"),
                },
            )

            # ğŸ”¥ æ ¹æ®æ˜¯å¦æœ‰ç°æœ‰sessionå†³å®šåˆ›å»ºæˆ–å¤ç”¨
            if existing_session_id and existing_thread_id:
                # ä½¿ç”¨ç°æœ‰sessionï¼Œé¿å…é‡å¤åˆ›å»º
                thread_id = existing_thread_id
                # é€šè¿‡thread_idè·å–sessionä¿¡æ¯
                session_data = await self.session_repo.get_session_by_thread_id(
                    existing_thread_id
                )
                if not session_data:
                    raise HTTPException(status_code=404, detail="æŒ‡å®šçš„sessionä¸å­˜åœ¨")
                url_param = session_data.url_param
                logger.info(
                    f"Using existing session: {existing_session_id}, thread_id: {thread_id}"
                )
            else:
                # åˆ›å»ºæ–°sessionï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                thread_id = str(uuid.uuid4())
                session_data, url_param = await self.session_repo.create_session(
                    thread_id=thread_id,
                    frontend_uuid=request.frontend_uuid,
                    visitor_id=request.visitor_id,
                    user_id=request.user_id,
                    initial_question=request.message,
                    research_config=research_config,
                    model_config=model_config,
                    output_config=output_config,
                )
                logger.info(
                    f"Created new session: {session_data.id}, thread_id: {thread_id}"
                )

            # åˆ›å»ºæ‰§è¡Œè®°å½•
            execution_record = await self.session_repo.create_execution_record(
                session_id=session_data.id,
                frontend_context_uuid=request.frontend_context_uuid,
                action_type=ActionType.CREATE,
                user_message=request.message,
            )
            execution_id = execution_record.execution_id

            # ğŸ”¥ ç§»é™¤é‡å¤çš„navigationäº‹ä»¶å‘é€
            # research_create_apiå·²ç»å‘é€äº†åŒ…å«session_idçš„navigationäº‹ä»¶
            # è¿™é‡Œä¸å†é‡å¤å‘é€ï¼Œé¿å…åŒé‡navigationäº‹ä»¶é—®é¢˜

            # å‡†å¤‡LangGraphåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [{"role": "user", "content": request.message}],
                "research_topic": request.message,
                "locale": output_config.get("language", "zh-CN"),
                "auto_accepted_plan": research_config.get(
                    "auto_accepted_plan", False
                ),  # ç”¨æˆ·å¯é…ç½®ï¼Œé»˜è®¤éœ€è¦ç¡®è®¤
                "enable_background_investigation": research_config.get(
                    "enable_background_investigation", True
                ),
                "plan_iterations": 0,
            }

            # è·å–LangGraphå®ä¾‹
            graph = await self._get_graph()

            # å¤„ç†LangGraphæµå¼æ‰§è¡Œ - ç›´æ¥æ‰§è¡Œï¼Œæ— éœ€é¢„åˆ›å»ºcheckpoint
            async for event in self._process_langgraph_stream(
                graph,
                initial_state,
                thread_id,
                execution_id,
                request,
                execution_type="create",
            ):
                yield event

        except Exception as e:
            logger.error(f"åˆ›å»ºç ”ç©¶æµå¤±è´¥: {e}")
            yield self._make_research_event("error", {
                "error_code": "CREATE_STREAM_ERROR",
                "error_message": str(e),
                "error_details": {"error_type": type(e).__name__},
                "thread_id": "",
                "execution_id": "",
                "retry_after": 30,
                "suggestions": ["æ£€æŸ¥è¯·æ±‚å‚æ•°", "ç¨åé‡è¯•"],
                "timestamp": self._get_current_timestamp(),
            })

    async def continue_research_stream(
        self, request: ResearchStreamRequest
    ) -> AsyncGenerator[Dict[str, str], None]:
        """ç»§ç»­ç°æœ‰çš„ç ”ç©¶æµ - æç®€åŒ–å®ç°"""
        try:
            # è·å–thread_id
            thread_id = request.thread_id
            if not thread_id and request.url_param:
                session = await self.session_repo.get_session_by_url_param(request.url_param)
                if not session:
                    raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
                thread_id = session.thread_id

            if not thread_id:
                raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›thread_idæˆ–url_param")

            logger.info(f"ğŸ” Continue research stream for thread_id: {thread_id}")

            # åˆ›å»ºæ‰§è¡Œè®°å½•
            session = await self.session_repo.get_session_by_thread_id(thread_id)
            if not session:
                raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

            execution_record = await self.session_repo.create_execution_record(
                session_id=session.id,
                frontend_context_uuid=request.frontend_context_uuid,
                action_type=ActionType.CONTINUE,
                user_message=request.message,
            )
            execution_id = execution_record.execution_id

            # è·å–LangGraphå®ä¾‹
            graph = await self._get_graph()
            
            # æ„é€ continueçŠ¶æ€
            initial_state = {
                "messages": [{"role": "user", "content": request.message}],
                "research_topic": request.message,
            }

            # å¤„ç†LangGraphæµå¼æ‰§è¡Œ
            async for event in self._process_langgraph_stream(
                graph,
                initial_state,
                thread_id,
                execution_id,
                request,
                execution_type="continue",
            ):
                yield event

        except Exception as e:
            logger.error(f"Continue research stream failed: {e}")
            yield self._make_research_event("error", {
                "error_code": "CONTINUE_STREAM_ERROR",
                "error_message": str(e),
                "error_details": {"error_type": type(e).__name__},
                "thread_id": request.thread_id or "",
                "execution_id": "",
                "retry_after": 30,
                "suggestions": ["æ£€æŸ¥thread_id", "ç¡®è®¤ä¼šè¯å­˜åœ¨", "ç¨åé‡è¯•"],
                "timestamp": self._get_current_timestamp(),
            })


# ä¾èµ–æ³¨å…¥
async def get_session_repository_dependency() -> SessionRepository:
    """è·å–SessionRepositoryä¾èµ–"""
    import os
    from dotenv import load_dotenv

    load_dotenv()
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        raise HTTPException(status_code=500, detail="æ•°æ®åº“é…ç½®é”™è¯¯")

    return get_session_repository(db_url)


# APIç«¯ç‚¹
@router.post("/stream")
async def research_stream(
    request: ResearchStreamRequest,
    session_repo: SessionRepository = Depends(get_session_repository_dependency),
):
    """ç»Ÿä¸€ç ”ç©¶æµå¼æ¥å£"""
    service = ResearchStreamService(session_repo)

    if request.action == ActionType.CREATE:
        event_generator = service.create_research_stream(request)
    else:
        event_generator = service.continue_research_stream(request)

    async def stream_events():
        async for event in event_generator:
            # SSEæ ¼å¼
            yield f"event: {event['event']}\n"
            yield f"data: {event['data']}\n\n"

    return StreamingResponse(
        stream_events(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
    )


@router.get("/workspace/{url_param}")
async def get_workspace_data(
    url_param: str,
    session_repo: SessionRepository = Depends(get_session_repository_dependency),
):
    """è·å–å·¥ä½œåŒºçŠ¶æ€æ¥å£"""
    try:
        # é€šè¿‡url_paramè·å–ä¼šè¯ä¿¡æ¯
        session = await session_repo.get_session_by_url_param(url_param)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        # è·å–æ¶ˆæ¯å†å²
        messages_data = await session_repo.get_messages_by_session_id(session.id)

        # è·å–æ‰§è¡Œè®°å½•
        executions_data = await session_repo.get_execution_records_by_session_id(
            session.id
        )

        # ğŸ”¥ è·å–artifacts
        artifacts_data = []
        try:
            async with await session_repo.get_connection() as conn:
                cursor = conn.cursor()
                await cursor.execute(
                    """
                    SELECT artifact_id, type, title, description, content, 
                           content_format, source_agent, created_at
                    FROM artifact_storage 
                    WHERE session_id = %s 
                    ORDER BY created_at DESC
                """,
                    (session.id,),
                )
                artifacts_rows = await cursor.fetchall()

                artifacts_data = [
                    {
                        "id": row["artifact_id"],
                        "type": row["type"],
                        "title": row["title"],
                        "description": row["description"],
                        "content": row["content"],
                        "format": row["content_format"],
                        "source_agent": row["source_agent"],
                        "created_at": (
                            row["created_at"].isoformat() if row["created_at"] else None
                        ),
                    }
                    for row in artifacts_rows
                ]
        except Exception as e:
            logger.error(f"è·å–artifactså¤±è´¥: {e}")

        # è·å–é…ç½®
        config = await session_repo.get_session_config(session.id)

        return {
            "thread_id": session.thread_id,
            "url_param": session.url_param,
            "status": (
                session.status
                if isinstance(session.status, str)
                else session.status.value
            ),
            "session_metadata": {
                "created_at": session.created_at.isoformat(),
                "last_updated": session.updated_at.isoformat(),
                "total_interactions": len(executions_data),
                "execution_history": [
                    {
                        "execution_id": exec.get("execution_id"),
                        "action_type": exec.get("action_type"),
                        "start_time": (
                            exec.get("created_at").isoformat()
                            if exec.get("created_at")
                            else None
                        ),
                        "status": exec.get("status"),
                    }
                    for exec in executions_data
                ],
            },
            "messages": [
                {
                    "id": msg.get("message_id"),
                    "content": msg.get("content"),
                    "role": msg.get("role"),
                    "timestamp": (
                        msg.get("timestamp").isoformat()
                        if msg.get("timestamp")
                        else None
                    ),
                    "metadata": {
                        "frontend_context_uuid": msg.get("frontend_context_uuid"),
                        "source_agent": msg.get("source_agent"),
                    },
                }
                for msg in messages_data
            ],
            "artifacts": artifacts_data,
            "config": {
                "current_config": (
                    {
                        "research_config": config.research_config or {},
                        "model_config": config.model_config or {},
                        "output_config": config.output_config or {},
                        "user_preferences": config.user_preferences or {},
                    }
                    if config
                    else {}
                ),
                "config_history": [],
            },
            "execution_stats": {
                "total_tokens_used": sum(
                    (exec.get("input_tokens", 0) or 0)
                    + (exec.get("output_tokens", 0) or 0)
                    for exec in executions_data
                ),
                "total_cost": sum(
                    exec.get("total_cost", 0) or 0 for exec in executions_data
                ),
                "average_response_time": (
                    sum(exec.get("duration_ms", 0) or 0 for exec in executions_data)
                    / len(executions_data)
                    if executions_data
                    else 0
                ),
                "model_usage_breakdown": {},
            },
            "permissions": {
                "can_modify": True,
                "can_share": True,
                "can_export": True,
                "can_delete": True,
            },
        }

    except Exception as e:
        logger.error(f"è·å–å·¥ä½œåŒºæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
