#!/usr/bin/env python3
"""
Research Ask API - ç»Ÿä¸€çš„ç ”ç©¶è¯¢é—®æ¥å£
æ”¯æŒinitialï¼ˆæ–°å»ºç ”ç©¶ï¼‰å’Œfollowupï¼ˆè¿½é—®ï¼‰ä¸¤ç§åœºæ™¯
æ”¯æŒstreamæ¨¡å¼ï¼ˆSSEæµï¼‰å’Œä¼ ç»ŸJSONå“åº”
"""

import asyncio
import os
import uuid
from datetime import datetime
from typing import Dict, Any, Optional, Literal, AsyncGenerator
import logging
from dataclasses import dataclass
import json

from fastapi import APIRouter, HTTPException, Depends, Query, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field, model_validator
from dotenv import load_dotenv

from src.server.repositories.session_repository import (
    SessionRepository,
    get_session_repository,
    ActionType,
    ExecutionStatus,
)
from src.server.supabase_auth_api import get_current_user
from src.utils.logger import get_logger

logger = get_logger("research_ask_api")

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/research", tags=["research"])


# è¯·æ±‚å’Œå“åº”æ¨¡å‹
class ResearchAskRequest(BaseModel):
    question: str = Field(
        ..., min_length=0, max_length=2000, description="ç”¨æˆ·ç ”ç©¶é—®é¢˜"
    )
    ask_type: Literal["initial", "followup"] = Field(
        ..., description="è¯¢é—®ç±»å‹ï¼šinitial=æ–°å»ºç ”ç©¶ï¼Œfollowup=è¿½é—®"
    )
    frontend_uuid: str = Field(..., description="å‰ç«¯ç”Ÿæˆçš„UUID")
    visitor_id: str = Field(..., description="è®¿å®¢ID")
    user_id: Optional[str] = Field(None, description="ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰")
    config: Optional[Dict[str, Any]] = Field(
        default_factory=dict, description="é…ç½®å‚æ•°"
    )

    # followupåœºæ™¯çš„å¿…è¦ä¿¡æ¯
    session_id: Optional[int] = Field(None, description="followupæ—¶å¿…é¡»æä¾›çš„ä¼šè¯ID")
    thread_id: Optional[str] = Field(None, description="followupæ—¶å¿…é¡»æä¾›çš„çº¿ç¨‹ID")
    url_param: Optional[str] = Field(None, description="followupæ—¶å¿…é¡»æä¾›çš„URLå‚æ•°")

    # ğŸ”¥ æ·»åŠ interrupt_feedbackæ”¯æŒ
    interrupt_feedback: Optional[str] = Field(
        None,
        description="HITL interruptåé¦ˆï¼šaccepted, edit_plan, skip_research, reaskç­‰",
    )

    @model_validator(mode="after")
    def validate_question_for_hitl(self):
        """æ¡ä»¶éªŒè¯ï¼šHITLåœºæ™¯å…è®¸questionä¸ºç©ºï¼Œå¦åˆ™è¦æ±‚æœ‰å†…å®¹"""
        # å¦‚æœæœ‰interrupt_feedbackï¼Œå…è®¸questionä¸ºç©º
        if self.interrupt_feedback:
            return self
        # å¦åˆ™è¦æ±‚questionæœ‰å†…å®¹
        if not self.question.strip():
            raise ValueError("questionä¸èƒ½ä¸ºç©ºï¼ˆé™¤éæä¾›interrupt_feedbackï¼‰")
        return self


class ResearchAskResponse(BaseModel):
    ask_type: str = Field(..., description="è¯¢é—®ç±»å‹")
    url_param: str = Field(..., description="URLå‚æ•°")
    frontend_uuid: str = Field(..., description="å‰ç«¯UUID")
    session_id: int = Field(..., description="ä¼šè¯ID")
    thread_id: str = Field(..., description="çº¿ç¨‹ID")
    workspace_url: str = Field(..., description="å·¥ä½œåŒºURL")
    estimated_duration: int = Field(default=120, description="é¢„ä¼°å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰")
    created_at: str = Field(..., description="åˆ›å»ºæ—¶é—´")


class ResearchAskService:
    """ç»Ÿä¸€çš„ç ”ç©¶è¯¢é—®æœåŠ¡"""

    def __init__(self, session_repo: SessionRepository):
        self.session_repo = session_repo

    def ask_research(self, request: ResearchAskRequest, stream: bool = False):
        """
        ç»Ÿä¸€çš„ç ”ç©¶è¯¢é—®å¤„ç†
        æ ¹æ®ask_typeåˆ†åˆ«å¤„ç†initialå’Œfollowupåœºæ™¯
        æ”¯æŒstreamæ¨¡å¼å’Œä¼ ç»ŸJSONå“åº”
        """
        if stream:
            # ğŸ”¥ æµå¼æ¨¡å¼ï¼šè¿”å›å¼‚æ­¥ç”Ÿæˆå™¨
            return self._handle_stream_ask(request)
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šè¿”å›åç¨‹
            return self._handle_non_stream_ask(request)

    async def _handle_non_stream_ask(self, request: ResearchAskRequest):
        """å¤„ç†éæµå¼è¯·æ±‚"""
        try:
            if request.ask_type == "initial":
                return await self._handle_initial_ask(request)
            elif request.ask_type == "followup":
                return await self._handle_followup_ask(request)
            else:
                raise HTTPException(
                    status_code=400, detail=f"ä¸æ”¯æŒçš„ask_type: {request.ask_type}"
                )

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"ç ”ç©¶è¯¢é—®å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"ç ”ç©¶è¯¢é—®å¤±è´¥: {str(e)}")

    async def _handle_stream_ask(
        self, request: ResearchAskRequest
    ) -> AsyncGenerator[str, None]:
        """
        å¤„ç†æµå¼askè¯·æ±‚ - æŒ‰ç…§æœ€ä½³å®è·µé‡æ–°å®ç°
        å…³é”®è®¾è®¡ï¼š
        1. äº‹åŠ¡å‰ç½®ï¼šsessionåˆ›å»ºå’Œcommitåœ¨æµå¼€å§‹å‰å®Œæˆ
        2. ç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥å’ŒæœåŠ¡å®ä¾‹
        3. å¤ç”¨ç°æœ‰çš„ResearchStreamService
        4. æ·»åŠ å¿ƒè·³ä¿æ´»å’Œå¼‚å¸¸å¤„ç†
        """
        session_data = None
        thread_id = None
        url_param = None

        try:
            logger.info(f"ğŸš€ Starting stream ask: {request.ask_type}")

            # ğŸ”¥ æ­¥éª¤1ï¼šäº‹åŠ¡å‰ç½® - åœ¨æµå¼€å§‹å‰å®Œæˆsessionåˆ›å»ºå’Œcommit
            if request.ask_type == "initial":
                session_data, thread_id, url_param = await self._create_initial_session(
                    request
                )
                logger.info(
                    f"Pre-created initial session: {session_data.id}, thread_id: {thread_id}"
                )
            elif request.ask_type == "followup":
                session_data, thread_id, url_param = (
                    await self._prepare_followup_session(request)
                )
                logger.info(
                    f"Pre-prepared followup session: {session_data.id}, thread_id: {thread_id}"
                )
            else:
                raise ValueError(f"Unsupported ask_type: {request.ask_type}")

            # å‘é€å¯¼èˆªäº‹ä»¶ï¼ˆå‰ç«¯éœ€è¦çš„URLä¿¡æ¯ï¼‰
            navigation_event = {
                "url_param": url_param,
                "thread_id": thread_id,
                "session_id": session_data.id,  # æ·»åŠ session_id
                "workspace_url": f"/workspace?id={url_param}",
                "frontend_uuid": request.frontend_uuid,
                "timestamp": datetime.now().isoformat(),
            }
            yield f"event: navigation\n"
            yield f"data: {json.dumps(navigation_event)}\n\n"

            # ğŸ”¥ æ­¥éª¤2ï¼šç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹èµ„æº
            async def stream_with_independent_resources():
                """åœ¨ç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥å’ŒæœåŠ¡"""
                import os
                from dotenv import load_dotenv

                load_dotenv()
                db_url = os.getenv("DATABASE_URL")
                if not db_url:
                    raise ValueError("DATABASE_URL not configured")

                # åˆ›å»ºç‹¬ç«‹çš„session repository
                independent_session_repo = get_session_repository(db_url)

                # åˆ›å»ºç‹¬ç«‹çš„ResearchStreamService
                from src.server.research_stream_api import (
                    ResearchStreamService,
                    ResearchStreamRequest,
                    ActionType as StreamActionType,
                )

                stream_service = ResearchStreamService(independent_session_repo)

                # æ„å»ºæµå¼è¯·æ±‚
                if request.ask_type == "initial":
                    stream_request = ResearchStreamRequest(
                        action=StreamActionType.CREATE,
                        message=request.question,
                        url_param=url_param,
                        frontend_uuid=request.frontend_uuid,
                        frontend_context_uuid=request.frontend_uuid,
                        visitor_id=request.visitor_id,
                        user_id=request.user_id,
                        config=self._build_stream_config(request.config),
                    )

                    # ä½¿ç”¨ç°æœ‰sessionä¿¡æ¯
                    async for event in stream_service.create_research_stream(
                        stream_request,
                        existing_session_id=session_data.id,
                        existing_thread_id=thread_id,
                    ):
                        yield f"event: {event['event']}\n"
                        yield f"data: {event['data']}\n\n"

                else:  # followup
                    stream_request = ResearchStreamRequest(
                        action=StreamActionType.CONTINUE,
                        message=request.question,
                        url_param=url_param,
                        thread_id=thread_id,
                        frontend_uuid=request.frontend_uuid,
                        frontend_context_uuid=request.frontend_uuid,
                        visitor_id=request.visitor_id,
                        user_id=request.user_id,
                        config=self._build_stream_config(request.config),
                        context=(
                            {"interrupt_feedback": request.interrupt_feedback}
                            if request.interrupt_feedback
                            else None
                        ),
                    )

                    async for event in stream_service.continue_research_stream(
                        stream_request
                    ):
                        yield f"event: {event['event']}\n"
                        yield f"data: {event['data']}\n\n"

            # ğŸ”¥ æ­¥éª¤3ï¼šæµå¼å¤„ç† + å¿ƒè·³ä¿æ´»
            last_heartbeat = asyncio.get_event_loop().time()
            heartbeat_interval = 30  # 30ç§’å¿ƒè·³é—´éš”

            async for data_chunk in stream_with_independent_resources():
                yield data_chunk

                # æ›´æ–°å¿ƒè·³æ—¶é—´
                last_heartbeat = asyncio.get_event_loop().time()

            # ğŸ”¥ ä¸å†å‘é€é¢å¤–çš„completeäº‹ä»¶
            # ResearchStreamServiceä¼šåœ¨LangGraphçœŸæ­£å®Œæˆæ—¶å‘é€completeäº‹ä»¶

            logger.info(f"âœ… Stream ask completed successfully: {thread_id}")

        except Exception as e:
            logger.error(f"âŒ Stream ask error: {e}")
            import traceback

            traceback.print_exc()

            # å‘é€é”™è¯¯äº‹ä»¶
            error_event = {
                "error_code": "STREAM_ERROR",
                "error_message": str(e),
                "thread_id": thread_id,
                "url_param": url_param,
                "timestamp": datetime.now().isoformat(),
            }

            try:
                yield f"event: error\n"
                yield f"data: {json.dumps(error_event)}\n\n"
            except:
                logger.error("Failed to send error event")

    async def _create_initial_session(self, request: ResearchAskRequest) -> tuple:
        """åˆ›å»ºinitial sessionçš„å‰ç½®é€»è¾‘"""
        # ç”Ÿæˆæ–°çš„thread_id
        thread_id = str(uuid.uuid4())

        # è§£æé…ç½®
        research_config, model_config, output_config = self._parse_config(
            request.config
        )

        # åˆ›å»ºæ–°ä¼šè¯
        session_mapping, url_param = await self.session_repo.create_session(
            thread_id=thread_id,
            frontend_uuid=request.frontend_uuid,
            visitor_id=request.visitor_id,
            user_id=request.user_id,
            initial_question=request.question,
            research_config=research_config,
            model_config=model_config,
            output_config=output_config,
        )

        logger.info(
            f"Created session for stream: {session_mapping.id}, thread_id: {thread_id}"
        )
        return session_mapping, thread_id, url_param

    async def _prepare_followup_session(self, request: ResearchAskRequest) -> tuple:
        """å‡†å¤‡followup sessionçš„å‰ç½®é€»è¾‘"""
        # éªŒè¯followupå¿…éœ€å‚æ•°
        if not all([request.session_id, request.thread_id, request.url_param]):
            raise HTTPException(
                status_code=400,
                detail="followupåœºæ™¯å¿…é¡»æä¾›session_id, thread_id, url_param",
            )

        # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨
        session_overview = await self.session_repo.get_session_overview(
            request.url_param
        )
        if not session_overview:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        # éªŒè¯session_idæ˜¯å¦åŒ¹é…
        if session_overview["id"] != request.session_id:
            raise HTTPException(status_code=400, detail="session_idä¸åŒ¹é…")

        if session_overview["thread_id"] != request.thread_id:
            raise HTTPException(status_code=400, detail="thread_idä¸åŒ¹é…")

        # è·å–sessionæ•°æ®
        session_data = await self.session_repo.get_session_by_thread_id(
            request.thread_id
        )
        if not session_data:
            raise HTTPException(status_code=404, detail="Sessionæ•°æ®ä¸å­˜åœ¨")

        logger.info(
            f"Prepared followup session: {request.session_id}, thread_id: {request.thread_id}"
        )
        return session_data, request.thread_id, request.url_param

    def _build_stream_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºæµå¼è¯·æ±‚çš„é…ç½®"""
        research_config, model_config, output_config = self._parse_config(config)

        return {
            "research_config": research_config,
            "model_config": model_config,
            "output_config": output_config,
            # æ‰å¹³åŒ–é…ç½®ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            "auto_accepted_plan": research_config.get("auto_accepted_plan", False),
            "enableBackgroundInvestigation": research_config.get(
                "enable_background_investigation", True
            ),
            "reportStyle": research_config.get("report_style", "academic"),
            "enableDeepThinking": research_config.get("enable_deep_thinking", False),
            "maxPlanIterations": research_config.get("max_plan_iterations", 3),
            "maxStepNum": research_config.get("max_step_num", 5),
            "maxSearchResults": research_config.get("max_search_results", 5),
            "outputFormat": output_config.get("output_format", "markdown"),
            "interrupt_feedback": config.get("interrupt_feedback", None),
        }

    async def _handle_initial_ask(
        self, request: ResearchAskRequest
    ) -> ResearchAskResponse:
        """å¤„ç†initialåœºæ™¯ - åˆ›å»ºæ–°çš„ç ”ç©¶ä¼šè¯"""
        logger.info(f"Processing initial ask: {request.question[:50]}...")

        # ç”Ÿæˆæ–°çš„thread_id
        thread_id = str(uuid.uuid4())

        # è§£æé…ç½®
        research_config, model_config, output_config = self._parse_config(
            request.config
        )

        # åˆ›å»ºæ–°ä¼šè¯
        session_mapping, url_param = await self.session_repo.create_session(
            thread_id=thread_id,
            frontend_uuid=request.frontend_uuid,
            visitor_id=request.visitor_id,
            user_id=request.user_id,
            initial_question=request.question,
            research_config=research_config,
            model_config=model_config,
            output_config=output_config,
        )

        # å¯åŠ¨åå°ç ”ç©¶ä»»åŠ¡
        asyncio.create_task(
            self._start_background_research_task(
                thread_id=thread_id,
                session_id=session_mapping.id,
                question=request.question,
                frontend_uuid=request.frontend_uuid,
                visitor_id=request.visitor_id,
                research_config=research_config,
                model_config=model_config,
                output_config=output_config,
                existing_session_id=session_mapping.id,  # ğŸ”¥ ä¼ é€’ç°æœ‰session_id
                existing_thread_id=thread_id,  # ğŸ”¥ ä¼ é€’ç°æœ‰thread_id
            )
        )

        # æ„å»ºå“åº”
        response = ResearchAskResponse(
            ask_type=request.ask_type,
            url_param=url_param,
            frontend_uuid=request.frontend_uuid,
            session_id=session_mapping.id,
            thread_id=thread_id,
            workspace_url=f"/workspace?id={url_param}",
            estimated_duration=self._estimate_research_duration(request.question),
            created_at=datetime.now().isoformat(),
        )

        logger.info(
            f"Successfully created initial research session: {response.url_param}"
        )
        return response

    async def _handle_followup_ask(
        self, request: ResearchAskRequest
    ) -> ResearchAskResponse:
        """å¤„ç†followupåœºæ™¯ - åœ¨ç°æœ‰ä¼šè¯ä¸­è¿½é—®"""
        logger.info(f"Processing followup ask: {request.question[:50]}...")

        # éªŒè¯followupå¿…éœ€å‚æ•°
        if not all([request.session_id, request.thread_id, request.url_param]):
            raise HTTPException(
                status_code=400,
                detail="followupåœºæ™¯å¿…é¡»æä¾›session_id, thread_id, url_param",
            )

        # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨ - ä½¿ç”¨ get_session_overview æ›¿ä»£
        session_overview = await self.session_repo.get_session_overview(
            request.url_param
        )
        if not session_overview:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        # éªŒè¯session_idæ˜¯å¦åŒ¹é…
        if session_overview["id"] != request.session_id:
            raise HTTPException(status_code=400, detail="session_idä¸åŒ¹é…")

        if session_overview["thread_id"] != request.thread_id:
            raise HTTPException(status_code=400, detail="thread_idä¸åŒ¹é…")

        # è§£æé…ç½®ï¼ˆfollowupå¯èƒ½æœ‰æ–°çš„é…ç½®ï¼‰
        research_config, model_config, output_config = self._parse_config(
            request.config
        )

        # å¯åŠ¨followupç ”ç©¶ä»»åŠ¡ï¼ˆå¤ç”¨ç°æœ‰sessionå’Œthread_idï¼‰
        asyncio.create_task(
            self._start_followup_research_task(
                thread_id=request.thread_id,
                session_id=request.session_id,
                question=request.question,
                frontend_uuid=request.frontend_uuid,
                visitor_id=request.visitor_id,
                research_config=research_config,
                model_config=model_config,
                output_config=output_config,
            )
        )

        # æ„å»ºå“åº”ï¼ˆå¤ç”¨ç°æœ‰ä¼šè¯ä¿¡æ¯ï¼‰
        response = ResearchAskResponse(
            ask_type=request.ask_type,
            url_param=request.url_param,
            frontend_uuid=request.frontend_uuid,
            session_id=request.session_id,
            thread_id=request.thread_id,
            workspace_url=f"/workspace?id={request.url_param}",
            estimated_duration=self._estimate_research_duration(request.question),
            created_at=datetime.now().isoformat(),
        )

        logger.info(f"Successfully processed followup ask: {response.url_param}")
        return response

    def _parse_config(self, config: Dict[str, Any]) -> tuple:
        """è§£æé…ç½®å‚æ•° - æ”¯æŒåµŒå¥—å’Œæ‰å¹³ç»“æ„"""
        research_config = {
            "auto_accepted_plan": (
                config.get("research", {}).get("auto_accepted_plan")
                or config.get("auto_accepted_plan")
                or False
            ),
            "enable_background_investigation": (
                config.get("research", {}).get("enable_background_investigation")
                or config.get("enable_background_investigation")
                or True
            ),
            "report_style": (
                config.get("research", {}).get("report_style")
                or config.get("report_style")
                or "academic"
            ),
            "enable_deep_thinking": (
                config.get("research", {}).get("enable_deep_thinking")
                or config.get("enable_deep_thinking")
                or False
            ),
            "max_plan_iterations": (
                config.get("research", {}).get("max_research_depth")
                or config.get("max_plan_iterations")
                or 3
            ),
            "max_step_num": (
                config.get("research", {}).get("max_step_num")
                or config.get("max_step_num")
                or 5
            ),
            "max_search_results": (
                config.get("research", {}).get("max_search_results")
                or config.get("max_search_results")
                or 5
            ),
        }

        model_config = config.get("model", {})
        output_config = config.get(
            "output", {"language": "zh-CN", "output_format": "markdown"}
        )

        return research_config, model_config, output_config

    async def _start_background_research_task(
        self,
        thread_id: str,
        session_id: int,
        question: str,
        frontend_uuid: str,
        visitor_id: str,
        research_config: Dict[str, Any],
        model_config: Dict[str, Any],
        output_config: Dict[str, Any],
        existing_session_id: int,  # ğŸ”¥ æ–°å¢å‚æ•°
        existing_thread_id: str,  # ğŸ”¥ æ–°å¢å‚æ•°
    ):
        """å¯åŠ¨åå°ç ”ç©¶ä»»åŠ¡ï¼ˆinitialåœºæ™¯ï¼‰"""
        try:
            logger.info(f"Starting background research task for thread_id: {thread_id}")

            # åˆ›å»ºæ‰§è¡Œè®°å½•
            execution_record = await self.session_repo.create_execution_record(
                session_id=session_id,
                frontend_context_uuid=frontend_uuid,
                action_type=ActionType.CREATE,
                user_message=question,
                model_used=model_config.get("model_name", "claude-3-5-sonnet"),
                provider=model_config.get("provider", "anthropic"),
            )

            logger.info(f"Created execution record: {execution_record.execution_id}")

            # ğŸ”¥ ä½¿ç”¨ResearchStreamServiceæ¥å¤„ç†åå°ä»»åŠ¡
            from src.server.research_stream_api import (
                ResearchStreamService,
                ResearchStreamRequest,
                ActionType as StreamActionType,
            )

            stream_service = ResearchStreamService(self.session_repo)

            # æ„å»ºè¯·æ±‚å¯¹è±¡
            stream_request = ResearchStreamRequest(
                action=StreamActionType.CREATE,
                message=question,
                url_param=None,
                frontend_uuid=frontend_uuid,
                frontend_context_uuid=frontend_uuid,
                visitor_id=visitor_id,
                user_id=None,
                config={
                    "research_config": research_config,
                    "model_config": model_config,
                    "output_config": output_config,
                },
            )

            # ğŸ”¥ ä¼ é€’ç°æœ‰sessionå‚æ•°ï¼Œé¿å…é‡å¤åˆ›å»º
            async for event in stream_service.create_research_stream(
                stream_request,
                existing_session_id=existing_session_id,
                existing_thread_id=existing_thread_id,
            ):
                logger.debug(
                    f"Background task event: {event.get('event', 'unknown') if isinstance(event, dict) else str(event)}"
                )

                if isinstance(event, dict):
                    event_type = event.get("event")
                    if event_type == "complete":
                        await self.session_repo.update_execution_record(
                            execution_id=execution_record.execution_id,
                            status=ExecutionStatus.COMPLETED,
                            end_time=datetime.now(),
                        )
                        logger.info(
                            f"Background task completed for thread_id: {thread_id}"
                        )
                        break
                    elif event_type == "error":
                        error_data = event.get("data", {})
                        if isinstance(error_data, str):
                            try:
                                error_data = json.loads(error_data)
                            except:
                                error_data = {"error_message": error_data}

                        await self.session_repo.update_execution_record(
                            execution_id=execution_record.execution_id,
                            status=ExecutionStatus.ERROR,
                            error_message=error_data.get(
                                "error_message", "Unknown error"
                            ),
                            end_time=datetime.now(),
                        )
                        logger.error(
                            f"Background task failed for thread_id: {thread_id}"
                        )
                        break

        except Exception as e:
            logger.error(f"Background research task failed for {thread_id}: {e}")
            try:
                await self.session_repo.update_execution_record(
                    execution_id=(
                        execution_record.execution_id
                        if "execution_record" in locals()
                        else thread_id
                    ),
                    status=ExecutionStatus.ERROR,
                    error_message=str(e),
                    end_time=datetime.now(),
                )
            except:
                pass

    async def _start_followup_research_task(
        self,
        thread_id: str,
        session_id: int,
        question: str,
        frontend_uuid: str,
        visitor_id: str,
        research_config: Dict[str, Any],
        model_config: Dict[str, Any],
        output_config: Dict[str, Any],
    ):
        """å¯åŠ¨followupç ”ç©¶ä»»åŠ¡"""
        try:
            logger.info(f"Starting followup research task for thread_id: {thread_id}")

            # åˆ›å»ºæ‰§è¡Œè®°å½•
            execution_record = await self.session_repo.create_execution_record(
                session_id=session_id,
                frontend_context_uuid=frontend_uuid,
                action_type=ActionType.CONTINUE,  # ä½¿ç”¨CONTINUEè¡¨ç¤ºfollowup
                user_message=question,
                model_used=model_config.get("model_name", "claude-3-5-sonnet"),
                provider=model_config.get("provider", "anthropic"),
            )

            logger.info(
                f"Created followup execution record: {execution_record.execution_id}"
            )

            # ğŸ”¥ ä½¿ç”¨ResearchStreamServiceçš„continue_research_streamæ–¹æ³•
            from src.server.research_stream_api import (
                ResearchStreamService,
                ResearchStreamRequest,
                ActionType as StreamActionType,
            )

            stream_service = ResearchStreamService(self.session_repo)

            # è·å–url_param
            session = await self.session_repo.get_session_by_thread_id(thread_id)
            if not session:
                raise ValueError(f"Session not found for thread_id: {thread_id}")
            url_param = session.url_param

            # æ„å»ºè¯·æ±‚å¯¹è±¡
            stream_request = ResearchStreamRequest(
                action=StreamActionType.CONTINUE,
                message=question,
                url_param=url_param,
                frontend_uuid=frontend_uuid,
                frontend_context_uuid=frontend_uuid,
                visitor_id=visitor_id,
                user_id=None,
                config={
                    "research_config": research_config,
                    "model_config": model_config,
                    "output_config": output_config,
                },
            )

            # æ‰§è¡Œfollowupæµå¼å¤„ç†
            async for event in stream_service.continue_research_stream(stream_request):
                logger.debug(
                    f"Followup task event: {event.get('event', 'unknown') if isinstance(event, dict) else str(event)}"
                )

                if isinstance(event, dict):
                    event_type = event.get("event")
                    if event_type == "complete":
                        await self.session_repo.update_execution_record(
                            execution_id=execution_record.execution_id,
                            status=ExecutionStatus.COMPLETED,
                            end_time=datetime.now(),
                        )
                        logger.info(
                            f"Followup task completed for thread_id: {thread_id}"
                        )
                        break
                    elif event_type == "error":
                        error_data = event.get("data", {})
                        if isinstance(error_data, str):
                            try:
                                error_data = json.loads(error_data)
                            except:
                                error_data = {"error_message": error_data}

                        await self.session_repo.update_execution_record(
                            execution_id=execution_record.execution_id,
                            status=ExecutionStatus.ERROR,
                            error_message=error_data.get(
                                "error_message", "Unknown error"
                            ),
                            end_time=datetime.now(),
                        )
                        logger.error(f"Followup task failed for thread_id: {thread_id}")
                        break

        except Exception as e:
            logger.error(f"Followup research task failed for {thread_id}: {e}")
            try:
                await self.session_repo.update_execution_record(
                    execution_id=(
                        execution_record.execution_id
                        if "execution_record" in locals()
                        else thread_id
                    ),
                    status=ExecutionStatus.ERROR,
                    error_message=str(e),
                    end_time=datetime.now(),
                )
            except:
                pass

    def _estimate_research_duration(self, question: str) -> int:
        """æ ¹æ®é—®é¢˜å¤æ‚åº¦ä¼°ç®—ç ”ç©¶æ—¶é—´"""
        base_duration = 60

        if len(question) > 100:
            base_duration += 30
        if len(question) > 200:
            base_duration += 30

        complex_keywords = ["åˆ†æ", "æ¯”è¾ƒ", "ç ”ç©¶", "è¯„ä¼°", "è°ƒæŸ¥", "æ·±å…¥", "å…¨é¢"]
        for keyword in complex_keywords:
            if keyword in question:
                base_duration += 20

        return min(base_duration, 300)


# ä¾èµ–æ³¨å…¥
async def get_session_repository_dependency() -> SessionRepository:
    """è·å–SessionRepositoryä¾èµ–"""
    load_dotenv()
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        raise HTTPException(status_code=500, detail="æ•°æ®åº“é…ç½®é”™è¯¯")

    return get_session_repository(db_url)


async def get_research_ask_service(
    session_repo: SessionRepository = Depends(get_session_repository_dependency),
) -> ResearchAskService:
    """è·å–ç ”ç©¶è¯¢é—®æœåŠ¡å®ä¾‹"""
    return ResearchAskService(session_repo)


# APIè·¯ç”±
@router.post("/ask")
async def ask_research(
    payload: ResearchAskRequest,
    http_request: Request,  # ğŸ”¥ æ·»åŠ Requestå‚æ•°ç”¨äºæ–­çº¿æ£€æµ‹
    stream: bool = Query(False, description="æ˜¯å¦å¯ç”¨æµå¼å“åº”"),
    current_user: dict = Depends(get_current_user),  # ğŸ‘ˆ æ·»åŠ å¼ºåˆ¶è®¤è¯
    service: ResearchAskService = Depends(get_research_ask_service),
):
    """
    ç»Ÿä¸€çš„ç ”ç©¶è¯¢é—®æ¥å£
    æ”¯æŒinitialï¼ˆæ–°å»ºç ”ç©¶ï¼‰å’Œfollowupï¼ˆè¿½é—®ï¼‰ä¸¤ç§åœºæ™¯
    æ”¯æŒstreamæ¨¡å¼ï¼ˆSSEæµï¼‰å’Œä¼ ç»ŸJSONå“åº”

    å‚æ•°ï¼š
    - stream=falseï¼ˆé»˜è®¤ï¼‰ï¼šè¿”å›JSONå“åº”ï¼Œåå°å¯åŠ¨ä»»åŠ¡
    - stream=trueï¼šç›´æ¥è¿”å›SSEæµï¼ŒåŒ…å«å®Œæ•´çš„ç ”ç©¶è¿‡ç¨‹
    """
    # ğŸ‘ˆ æ³¨å…¥ç”¨æˆ·IDåˆ°payload
    payload.user_id = current_user["user_id"]

    logger.info(
        f"Received {payload.ask_type} ask request: {payload.question[:50]}... (stream={stream}) for user: {current_user['user_id']}"
    )

    try:
        if stream:
            # ğŸ”¥ æµå¼æ¨¡å¼ï¼šæŒ‰ç…§æœ€ä½³å®è·µå®ç°
            async def stream_emitter():
                """æµå¼å“åº”å‘å°„å™¨ - åœ¨è¿™é‡Œæ·»åŠ æ–­çº¿æ£€æµ‹å’Œå¿ƒè·³ä¿æ´»"""
                try:
                    last_heartbeat = asyncio.get_event_loop().time()
                    heartbeat_interval = 30  # 30ç§’å¿ƒè·³é—´éš”

                    async for data_chunk in service.ask_research(payload, stream=True):
                        # ğŸ”¥ æ£€æµ‹å®¢æˆ·ç«¯æ–­çº¿
                        if await http_request.is_disconnected():
                            logger.info("Client disconnected, stopping stream")
                            break

                        yield data_chunk

                        # ğŸ”¥ å¿ƒè·³ä¿æ´»
                        current_time = asyncio.get_event_loop().time()
                        if current_time - last_heartbeat > heartbeat_interval:
                            heartbeat_event = ": heartbeat\n\n"  # SSE commentæ ¼å¼çš„å¿ƒè·³
                            yield heartbeat_event
                            last_heartbeat = current_time

                except Exception as e:
                    logger.error(f"Stream emitter error: {e}")
                    error_event = {
                        "error_code": "STREAM_EMITTER_ERROR",
                        "error_message": str(e),
                        "timestamp": datetime.now().isoformat(),
                    }
                    yield f"event: error\n"
                    yield f"data: {json.dumps(error_event)}\n\n"

            return StreamingResponse(
                stream_emitter(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "X-Accel-Buffering": "no",  # ğŸ”¥ å…³é—­Nginxç¼“å†²
                    "Access-Control-Allow-Origin": "*",  # ğŸ”¥ CORSæ”¯æŒ
                    "Access-Control-Allow-Headers": "Cache-Control",
                },
            )
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šè¿”å›JSONå“åº”
            response = await service.ask_research(payload, stream=False)
            logger.info(
                f"Successfully processed {payload.ask_type} ask: {response.url_param}"
            )
            return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error in ask_research: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")


@router.get("/test-stream")
async def test_stream():
    """æµ‹è¯•åŸºæœ¬çš„SSEæµåŠŸèƒ½"""

    async def simple_stream():
        for i in range(5):
            yield f'event: test\ndata: {{"count": {i}, "message": "Hello {i}"}}\n\n'
            await asyncio.sleep(1)
        yield f'event: complete\ndata: {{"finished": true}}\n\n'

    return StreamingResponse(
        simple_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
    )
